<!DOCTYPE html><html lang="en" mode="light" > <!-- The Head v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Underfitting, overfitting and model complexity | Anarthal Kernel</title><meta name="generator" content="Jekyll v4.1.1" /><meta property="og:title" content="Underfitting, overfitting and model complexity" /><meta name="author" content="anarthal" /><meta property="og:locale" content="en_US" /><meta name="description" content="In this post I will talk about the underfitting and overfitting phenomena, and how model complexity affects them. I will also explain the bias-variance trade-off." /><meta property="og:description" content="In this post I will talk about the underfitting and overfitting phenomena, and how model complexity affects them. I will also explain the bias-variance trade-off." /><link rel="canonical" href="https://anarthal.github.io/kernel/posts/underfitting-overfitting/" /><meta property="og:url" content="https://anarthal.github.io/kernel/posts/underfitting-overfitting/" /><meta property="og:site_name" content="Anarthal Kernel" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-07-16T00:00:00+02:00" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@type":"BlogPosting","url":"https://anarthal.github.io/kernel/posts/underfitting-overfitting/","author":{"@type":"Person","name":"anarthal"},"headline":"Underfitting, overfitting and model complexity","dateModified":"2020-07-16T00:00:00+02:00","datePublished":"2020-07-16T00:00:00+02:00","description":"In this post I will talk about the underfitting and overfitting phenomena, and how model complexity affects them. I will also explain the bias-variance trade-off.","mainEntityOfPage":{"@type":"WebPage","@id":"https://anarthal.github.io/kernel/posts/underfitting-overfitting/"},"@context":"https://schema.org"}</script> <!-- The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps Generated by: https://www.favicon-generator.org/ v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT license --><link rel="shortcut icon" href="/kernel/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/kernel/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/kernel/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/kernel/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/kernel/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/kernel/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/kernel/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/kernel/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/kernel/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/kernel/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/kernel/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/kernel/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/kernel/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/kernel/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/kernel/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/kernel/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/kernel/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/kernel/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/kernel/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/kernel/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="preload" as="style" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"> <!-- CSS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --><link rel="preload" as="style" href="/kernel/assets/css/post.css"><link rel="stylesheet" href="/kernel/assets/css/post.css"><link rel="preload" as="style" href="/kernel/assets/css/lib/bootstrap-toc.min.css"><link rel="stylesheet" href="/kernel/assets/css/lib/bootstrap-toc.min.css" /><link rel="preload" as="script" href="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" async></script> <!-- JS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --> <script src="/kernel/assets/js/post.min.js" async></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script> <script src="/kernel/app.js" defer></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column"> <!-- The Side Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="nav-wrapper"><div id="profile-wrapper" class="d-flex flex-column"><div id="avatar" class="d-flex justify-content-center"> <a href="/kernel/" alt="avatar"> <img src="/kernel/assets/img/sample/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="profile-text mt-3"><div class="site-title"> <a href="/kernel/">Anarthal Kernel</a></div><div class="site-subtitle font-italic">A blog on data science and programming</div></div></div><ul class="nav flex-column"><li class="nav-item d-flex justify-content-center "> <a href="/kernel/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/kernel/tabs/categories/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/kernel/tabs/tags/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/kernel/tabs/archives/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/kernel/tabs/about/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></li></ul></div><div class="sidebar-bottom d-flex flex-wrap justify-content-around mt-4"> <a href="https://github.com/anarthal" target="_blank"> <i class="fab fa-github-alt"></i> </a> <a href="https://www.linkedin.com/in/ruben-perez-hidalgo" target="_blank"> <i class="fab fa-linkedin"></i> </a></div></div><!-- The Top Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/kernel/"> Posts </a> </span> <span>Underfitting, overfitting and model complexity</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"> <!-- Fixed kramdown code highlight rendering: https://github.com/penibelst/jekyll-compress-html/issues/101 https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901 --><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Underfitting, overfitting and model complexity</h1><div class="post-meta text-muted d-flex flex-column"><div> Posted <span class="timeago" data-toggle="tooltip" data-placement="bottom" title="Thu, Jul 16, 2020, 12:00 AM +0200"> Jul 16, 2020 <i class="unloaded">2020-07-16T00:00:00+02:00</i> </span> by <span class="author"> anarthal </span></div><div> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Mon, Jul 20, 2020, 4:21 PM +0100"> Jul 20, 2020 <i class="unloaded">2020-07-20T17:21:13+02:00</i> </span></div></div><div class="post-content"><p>In this post I will talk about the underfitting and overfitting phenomena, and how model complexity affects them. I will also explain the bias-variance trade-off.</p><p>We will demonstrate these concepts with a binary classification example, where we will try to predict whether a forest elf will survive until being an adult or not based on two numeric features. <a href="https://www.kaggle.com/anarthal/underfitting-overfitting-and-model-complexity">This kernel</a> contains the full code listing for this post.</p><p>This posts assumes that you know basic machine learning concepts like <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a> or <a href="https://en.wikipedia.org/wiki/Binary_classification">binary classification</a>. We will use <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression</a> as a model to demonstrate these concepts. If you are not familiar with it, you may check <a href="/kernel/posts/logistic-regression/">my other post on logistic regression</a>. A basic faimiliarity with Python and <code class="language-plaintext highlighter-rouge">sklearn</code> is also necessary.</p><h2 id="model-performance">Model performance</h2><p>Underfitting and overfitting are two phenomena that cause a model to perform poorly. But how do we define model performance? When working in any machine learning task, it is vital to define an evaluation metric that allows us to assess how good our model is.</p><p>We will be dealing with binary classification, so we will employ <a href="https://developers.google.com/machine-learning/crash-course/classification/accuracy">classification accuracy</a> as a performance metric. Accuracy is defined as the ratio of correctly classified examples. It ranges between 0.0 and 1.0, and the higher, the better.</p><p>I will also use the term <em>error</em> throughout this post (as in “this model achieves a smaller error under these conditions”), meaning “the inverse of the performance metric”: the lower the metric, the higher the error.</p><h2 id="train-and-test-set">Train and test set</h2><p>To understand what over and underfitting is, we first need to explain the concept of train and test set.</p><p>Recall that in binary classification, we train our model on a collection of correctly labeled examples. This dataset is called the <strong>training set</strong>. After the model has been trained on this set, we can ask the model to make predictions on the examples in this dataset. Some of the examples will be classified correctly (most of them, hopefully), and some others won’t. We can thus calculate the error made by the model for this training set. This is called the <strong>training error</strong>.</p><p>However, doing well on the training set is not enough for a model to be good. We want our model to also do well on examples that hasn’t seen previously. In other words, we want our model to be able to generalize. The <strong>generalization error</strong> measures this capability.</p><p>The training error is not a good estimate for the generalization error, as it is based on examples the model has already seen. The model could “memorize” the training examples, achieving low training error, but fail to generalize. We will see later that this is called overfitting.</p><p>How can we obtain an unbiased estimation of the generalization error? Instead of using the entire labeled dataset to train the model, we will split it into two:</p><ul><li>The actual training set, used to train our model.</li><li>The test set, used to evaluate the model’s performance.</li></ul><p>After training the model, we will ask it to predict the classification labels for the examples in the test set. This will allow us to compute the <strong>test error</strong>, which is a better estimation of the generalization error.</p><h3 id="an-example">An example</h3><p>As promised, we will study how likely is a forest elf to surivive, given two physical features: <code class="language-plaintext highlighter-rouge">height</code> (which measures how tall the elf is) and <code class="language-plaintext highlighter-rouge">ear_length</code> (which should be obvious enough). We will try to predict whether the elf survives until being an adult or not.</p><p>As the savvy reader may have already realized, this is a made up dataset. It’s difficult to find real data that can show these concepts with just two features, which helps a lot with visualizations. The phenomena presented in this post are much more likely to happen in higher dimensional datasets.</p><p>Let’s visualize our dataset:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/kernel/assets/img/underfitting-overfitting/elf-dataset.png" alt="Dataset" /></p><p>Some observations:</p><ul><li>It seems like there are heavy interactions between the two features. The variables are not independent.</li><li>The features have been <a href="https://en.wikipedia.org/wiki/Feature_scaling">standardized</a>: they have zero mean and similar dispersion. This will help us when creating polynomial features, in the next section.</li><li>There is enough information to predict the class label using the two features. Negative examples are relatively grouped together, as positive examples are.</li></ul><p>The dataset contains 2000 examples. Let’s split it into train and test, with leaving 75% in the training set and 25% in the test set. We will use sklearn’s <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"><code class="language-plaintext highlighter-rouge">train_test_split</code></a>:</p><div class="language-py highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">df</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">...</span> <span class="c1"># df contains the features, y contains the ground-true labels
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> 
	<span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></table></code></div></div><p>Note that sklearn will randomly shuffle the dataset before performing the split. Passing a constant as <code class="language-plaintext highlighter-rouge">random_state</code> ensures consistent results between runs.</p><p>The following figure shows the aforementioned split. Lighter points belong to the training set, while darker ones have been assigned to the test set.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/kernel/assets/img/underfitting-overfitting/train-test-split.png" alt="Train-test split" /></p><h2 id="underfitting">Underfitting</h2><p>Let’s first build a plain logistic regression model and train it with our dataset (for an explanation about logistic regression, check out <a href="/kernel/posts/logistic-regression/">this post</a>):</p><div class="language-py highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></table></code></div></div><p>This model has an 86.9% accurancy on the training set and an 85.4% accuracy on the test set. That’s not optimal. Let’s visualize the decision boundary to get a feel of what is going on here:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/kernel/assets/img/underfitting-overfitting/underfitting.png" alt="Underfitting" /></p><p>Our model is too simple to achieve a good performance on this dataset. Recall that logistic regression is a linear model. It is trying to separate the two classes using a straight line, which isn’t quite right. Both the train and the test errors are high. This situation is called <strong>underfitting</strong>.</p><h2 id="increasing-model-complexity-polynomial-features">Increasing model complexity: polynomial features</h2><p>What can we do to make the situation better? We need to come up with a more complex model. One option would be to move away from logistic regression to a model that can learn non-linear decision boundaries by itself, like <a href="https://en.wikipedia.org/wiki/Random_forest">random forest</a> or <a href="https://xgboost.readthedocs.io/en/latest/">XGBoost</a>. The other option is to make a more complex logistic regression model by adding polynomial features. This will be the approach to follow here.</p><p>Recall that, to make predictions, logistic regression is computing the following:</p>\[z = \theta_0 + \theta_1 x_1 + \theta_2 x_2\] \[y_{prob} = \sigma(z)\]<p>Where \(\theta_i\) are the paremeters learnt by the model, \(x_0\) and \(x_1\) are our two input features and \(\sigma(z)\) is the <a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid function</a>. The output \(y_{prob}\) can be interpreted as a probability, thus predicting \(y = 1\) if \(y_{prob}\) is above a certain threshold (usually 0.5). Under these circumstances, it can be shown that the decision boundary is a straight line with the following equation:</p>\[\theta_0 + \theta_1 x_1 + \theta_2 x_2 = 0\]<p>The problem here is that the decision boundary shouldn’t be a linear function of the two features, but should also contain:</p><ul><li>Higher-degree polynomial terms, e.g. \(x_0^2\), \(x_0^3\) and so on.</li><li>Interaction terms, like \(x_0 x_1\) or \(x_0^2 x_1^3\).</li></ul><p>Resulting in a model like this:</p>\[z = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + \theta_3 x_1^2 + \theta_4 x_1 x_2 + \theta_5 x_2^2 + ...\] \[y_{prob} = \sigma(z)\]<p>We can make logistic regression do this by manually creating polynomial features. We will create additional columns in the <code class="language-plaintext highlighter-rouge">X_train</code> and <code class="language-plaintext highlighter-rouge">X_test</code> matrices, containing the values of \(x_1^2\), \(x_2^2\), \(x_0 x_1\) and so on until a certain degree. We will feed these features to the model as if they were additional variables.</p><p>Sklearn has a built-in <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html">polynomial feature creator</a>:</p><div class="language-py highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>

<span class="n">df</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">...</span> <span class="c1"># df contains the features, y contains the ground-true labels
</span><span class="n">X</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="mi">3</span><span class="p">).</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> 
	<span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></table></code></div></div><p>With this code we get <code class="language-plaintext highlighter-rouge">X</code> to have the original features, as well as several additional columns: \(x_1^2\), \(x_1^3\), \(x_2^2\), \(x_2^3\), \(x_1 x_2\), \(x_1^2 x_2\) and \(x_1 x_2^2\). The first argument to <code class="language-plaintext highlighter-rouge">PolynomialFeatures</code> is the maximum degree of the polynomial features to create. It is important that \(x_1\) and \(x_2\) have a similar range of values. Otherwise, polynomial terms may end up being extremely high or low. Having our data standardized solves this problem.</p><p>Fitting this model yields 96.7% accuracy on the training set and 95.4% on the training set. That’s much better! The decision boundary seems appropriate this time:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/kernel/assets/img/underfitting-overfitting/just-right.png" alt="Just right" /></p><h2 id="overfitting">Overfitting</h2><p>It seems like adding polynomial features helped the model performance. What happens if we use a very large degree polynomial? We will end up having an <strong>overfitting</strong> problem. Let’s see what happens when using a 15 degree polynomial (I’ve also turned regularization off, which increases the overfitting effect - we will talk about this later):</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/kernel/assets/img/underfitting-overfitting/overfitting.png" alt="Overfitting" /></p><p>This model achieves a 98.9% accuracy on the training set, but drops to 93% on the test set. The model has so much flexibility that is fitting an over-complicated decision boundary that does not generalize well. It is memorizing the training set, which proves useless when facing the test set.</p><h2 id="the-bias-variance-trade-off">The bias-variance trade-off</h2><p>As shown in the previous section, there is a trade-off in model complexity. Too complex models may overfit your data, while too simple ones are unable to represent it correctly. This trade-off between underfitting and overfitting is widely known as the bias-variance trade-off. But why is it called like that?</p><p>Bias and variance are two properties of statistical estimators:</p><ul><li><a href="https://en.wikipedia.org/wiki/Bias_of_an_estimator">Bias</a> estimates how far is the expected value of the estimator from the real value.</li><li><a href="https://en.wikipedia.org/wiki/Variance">Variance</a> measures the dispersion of the estimator around its expected value.</li></ul><p>In machine learning, we can decompose a model’s error in terms of these two properties:</p><ul><li>Bias tells us if the model is able to approximate the real underlying problem well. Our first model had high bias, as it was too simple to represent the dataset we were trying to classify. Having a high bias is thus a synonym of <strong>underfitting</strong>.</li><li>Variance tells us how much the predictions would vary if the training set changed slightly. Our third model had high variance, as it was memorizing the training set. If we had trained the model on a slightly different training set, the model would have changed significantly. A model with high variance is thus <strong>overfitting</strong> the training set.</li></ul><p>If you are interested in the mathematics underneath this decomposition, <a href="https://towardsdatascience.com/mse-and-bias-variance-decomposition-77449dd2ff55">this post</a> provides an in-depth explanation. The derivation is usually performed using the MSE loss function, common in regression. However, the bias and variance concepts are also applicable to classification, as we have seen.</p><p>As you saw in previous sections, changing the model complexity affects both bias and variance. More complex models tend to have higher variance and lower bias. On the other hand, simpler models will have lower variance but more bias. There is thus a <strong>trade-off</strong> between the two sources of error. To make a good model, we must balance the two terms wisely.</p><h3 id="factors-affecting-bias-and-variance">Factors affecting bias and variance</h3><p>Bias and variance may be affected by several factors:</p><ul><li>As already explained, increasing model complexity (also called <em>model capacity</em>) increases variance and lowers bias. This applies not only to switching between models and adding polynomial features, but also to certain hyperparameters. For example, decision trees have a hyperparameter controlling the depth of the tree. The bigger the value, the bigger the tree and the more complex the model. Increasing this value will tend to decrease bias and increase variance.</li><li>Adding more features tends to increase variance and decrease bias.</li><li>Making the training set bigger (i.e. gathering more data) usually decreases variance. It doesn’t have much effect on bias.</li><li><a href="https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a">Regularization</a> modifies the cost function to penalize complex models. Regularization makes variance smaller and bias higher. Sklearn’s <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"><code class="language-plaintext highlighter-rouge">LogisticRegression</code></a> uses regularization by default. It can be disabled by setting <code class="language-plaintext highlighter-rouge">penalty='none'</code>, and its magnitude is controlled by the <code class="language-plaintext highlighter-rouge">C</code> parameter (the smaller, the greater regularization effect).</li></ul><h2 id="diagnosing-bias-and-variance-problems">Diagnosing bias and variance problems</h2><p>It is easy to diagnose if your model suffers from high bias or high variance when you have only two features by plotting them. But what happens if your dataset has more than two dimensions? Then you should look at the training set and test set errors.</p><ul><li>If both the training set and test set errors are higher than what you would expect, it’s likely that you have a bias problem.</li><li>If the training set error is very low but the test set error is not, then your model is failing to generalize, thus having a variance problem.</li><li>If both errors are similar and as low as you would expect, then congratulations! Your model is just right.</li></ul><p>The below diagram shows the three logistic regression models we’ve come up with in this post, together with their train and test errors:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/kernel/assets/img/underfitting-overfitting/model-comparison.png" alt="Model comparison" /></p><h2 id="conclusion-and-further-reading">Conclusion and further reading</h2><p>Underfitting and overfitting, together with bias and variance, are very important concepts in machine learning. I hope this post helped you understand them better. You can also check <a href="https://www.kaggle.com/anarthal/underfitting-overfitting-and-model-complexity">this kernel</a> if you’re interested in the programming details.</p><p>Some further thoughts:</p><ul><li>You may have seen people splitting datasets into three parts: a training set, a cross validation or dev set and a test set. Cross-validation is a technique for estimating model performance and tuning hyperparameters. You can read more about it <a href="https://scikit-learn.org/stable/modules/cross_validation.html">here</a>.</li><li>We briefly talked about feature scaling and standardization. <a href="https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02">This post</a> may provide further insights about these preprocessing techniques.</li><li>Plotting learning curves is a technique to further diagnose if your model suffers from high bias or high variance. You can read <a href="https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/">this</a> for further info.</li></ul><p>Hope you have liked the post! Feedback and suggestions are always welcome.</p><h2 id="references">References</h2><ul><li>Machine Learning, Coursera course by Andrew Ng: <a href="https://www.coursera.org/learn/machine-learning/">https://www.coursera.org/learn/machine-learning/</a>.</li><li>4 Types of Classification Tasks in Machine Learning, by Jason Brownlee: <a href="https://machinelearningmastery.com/types-of-classification-in-machine-learning/">https://machinelearningmastery.com/types-of-classification-in-machine-learning/</a></li><li>How to Use Polynomial Feature Transforms for Machine Learning, by Jason Brownlee: <a href="https://machinelearningmastery.com/polynomial-features-transforms-for-machine-learning/">https://machinelearningmastery.com/polynomial-features-transforms-for-machine-learning/</a></li><li>MSE and Bias-Variance decomposition, by Maksym Zavershynskyi: https://towardsdatascience.com/mse-and-bias-variance-decomposition-77449dd2ff55</li><li>Holy Grail for Bias-Variance tradeoff, Overfitting &amp; Underfitting, by Juhi Ramzai: <a href="https://towardsdatascience.com/holy-grail-for-bias-variance-tradeoff-overfitting-underfitting-7fad64ab5d76">https://towardsdatascience.com/holy-grail-for-bias-variance-tradeoff-overfitting-underfitting-7fad64ab5d76</a></li><li>Scale, Standardize, or Normalize with Scikit-Learn, by Jeff Hale: <a href="https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02">https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02</a></li><li>How to use Learning Curves to Diagnose Machine Learning Model Performance, by Jason Brownlee: <a href="https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/">https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/</a></li><li>Sklearn documentation: <a href="https://scikit-learn.org/stable/">https://scikit-learn.org/stable/</a></li><li>XGBoost documentation: <a href="https://xgboost.readthedocs.io/en/latest/">https://xgboost.readthedocs.io/en/latest/</a></li></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/kernel/categories/data-science/'>Data Science</a>, <a href='/kernel/categories/machine-learning/'>Machine Learning</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/kernel/tags/machinelearning/" class="post-tag no-text-decoration" >machinelearning</a> <a href="/kernel/tags/classification/" class="post-tag no-text-decoration" >classification</a> <a href="/kernel/tags/supervised/" class="post-tag no-text-decoration" >supervised</a> <a href="/kernel/tags/sklearn/" class="post-tag no-text-decoration" >sklearn</a> <a href="/kernel/tags/python/" class="post-tag no-text-decoration" >python</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><!-- Post sharing snippet v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://anarthal.github.io/kernel/posts/underfitting-overfitting/" data-toggle="tooltip" data-placement="top" title="Linkedin" target="_blank"> <i class="fa-fw fab fa-linkedin"></i> </a> <a href="https://twitter.com/intent/tweet?text=Underfitting, overfitting and model complexity - Anarthal Kernel&url=https://anarthal.github.io/kernel/posts/underfitting-overfitting/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Underfitting, overfitting and model complexity - Anarthal Kernel&u=https://anarthal.github.io/kernel/posts/underfitting-overfitting/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Underfitting, overfitting and model complexity - Anarthal Kernel&url=https://anarthal.github.io/kernel/posts/underfitting-overfitting/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><!-- The Pannel on right side (Desktop views) v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><h3 data-toc-skip>Recent Update</h3><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/kernel/posts/underfitting-overfitting/">Underfitting, overfitting and model complexity</a></li><li><a href="/kernel/posts/logistic-regression/">Logistic regression</a></li></ul></div><div id="access-tags"><h3 data-toc-skip>Trending Tags</h3><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/kernel/tags/supervised/">supervised</a> <a class="post-tag" href="/kernel/tags/sklearn/">sklearn</a> <a class="post-tag" href="/kernel/tags/python/">python</a> <a class="post-tag" href="/kernel/tags/machinelearning/">machinelearning</a> <a class="post-tag" href="/kernel/tags/classification/">classification</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><h3 data-toc-skip class="pl-3 pt-2 mb-2">Contents</h3><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div id="post-extend-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"> <!-- Navigation buttons at the bottom of the post. v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --><div class="post-navigation d-flex justify-content-between"> <a href="/kernel/posts/logistic-regression/" class="btn btn-outline-primary"><p>Logistic regression</p></a> <span class="btn btn-outline-primary disabled"><p>-</p></span></div><!-- The Disqus lazy loading. Powered by: https://osvaldas.info/lazy-loading-disqus-comments v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung MIT License --><div id="disqus" class="pt-2 pb-4"><p class="font-italic text-center text-muted small">Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div><script src="/kernel/assets/js/lib/jquery.disqusloader.min.js"></script> <script> var options = { scriptUrl: '//anarthal-kernel.disqus.com/embed.js', disqusConfig: function() { this.page.url = 'https://anarthal.github.io/kernel/posts/underfitting-overfitting/'; this.page.identifier = '/posts/underfitting-overfitting/'; } }; $.disqusLoader('#disqus', options); </script> <!-- Recommend the other 3 posts according to the tags and categories of the current post, if the number is not enough, use the other latest posts to supplement. v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div id="related-posts" class="mt-4 mb-2 mb-sm-4 pb-2"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/kernel/posts/logistic-regression/"><div class="card-body"> <span class="timeago small"> Jul 8, 2020 <i class="unloaded">2020-07-08T00:00:00+02:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Logistic regression</h3><div class="text-muted small"><p>In this post I will talk about one of the most basic models in Machine Learning: logistic regression. This post doesn’t assume any previous knowledge of logistic regression. Some prior knowledge on...</p></div></div></a></div></div></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('#post-wrapper img'); const observer = lozad(imgs); observer.observe(); </script> <!-- The Footer v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2020 <a href="https://github.com/anarthal">Ruben Perez</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy/">Chirpy</a> theme.</p></div></div></footer></div><!-- The Search results v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/kernel/tags/supervised/">supervised</a> <a class="post-tag" href="/kernel/tags/sklearn/">sklearn</a> <a class="post-tag" href="/kernel/tags/python/">python</a> <a class="post-tag" href="/kernel/tags/machinelearning/">machinelearning</a> <a class="post-tag" href="/kernel/tags/classification/">classification</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <!-- The GA snippet v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-174570044-1', 'auto'); ga('send', 'pageview'); </script> <!-- Jekyll Simple Search loader v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/kernel/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://anarthal.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
