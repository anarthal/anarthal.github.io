<!DOCTYPE html><html lang="en" mode="light" > <!-- The Head v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta property="og:image" content="https://anarthal.github.io/kernel/assets/img/neural-networks/neural-networks-multiclass/layers.jpeg"><title>Deep dive into neural networks - multiclass classification | Anarthal Kernel</title><meta name="generator" content="Jekyll v4.1.1" /><meta property="og:title" content="Deep dive into neural networks - multiclass classification" /><meta name="author" content="anarthal" /><meta property="og:locale" content="en_US" /><meta name="description" content="How to perform multiclass classification using neural networks." /><meta property="og:description" content="How to perform multiclass classification using neural networks." /><link rel="canonical" href="https://anarthal.github.io/kernel/posts/neural-networks-multiclass/" /><meta property="og:url" content="https://anarthal.github.io/kernel/posts/neural-networks-multiclass/" /><meta property="og:site_name" content="Anarthal Kernel" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-08-23T00:00:00+02:00" /><meta name="google-site-verification" content="KNjn6jsPErqjkNHyg6KeODM3NUCCstBfD9OQgpT5lB4" /> <script type="application/ld+json"> {"@type":"BlogPosting","headline":"Deep dive into neural networks - multiclass classification","url":"https://anarthal.github.io/kernel/posts/neural-networks-multiclass/","datePublished":"2020-08-23T00:00:00+02:00","dateModified":"2020-08-23T00:00:00+02:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://anarthal.github.io/kernel/posts/neural-networks-multiclass/"},"author":{"@type":"Person","name":"anarthal"},"description":"How to perform multiclass classification using neural networks.","@context":"https://schema.org"}</script> <!-- The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps Generated by: https://www.favicon-generator.org/ v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT license --><link rel="shortcut icon" href="/kernel/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/kernel/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/kernel/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/kernel/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/kernel/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/kernel/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/kernel/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/kernel/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/kernel/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/kernel/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/kernel/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/kernel/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/kernel/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/kernel/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/kernel/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/kernel/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/kernel/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/kernel/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/kernel/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/kernel/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="preload" as="style" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"> <!-- CSS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --><link rel="preload" as="style" href="/kernel/assets/css/post.css"><link rel="stylesheet" href="/kernel/assets/css/post.css"><link rel="preload" as="style" href="/kernel/assets/css/lib/bootstrap-toc.min.css"><link rel="stylesheet" href="/kernel/assets/css/lib/bootstrap-toc.min.css" /><link rel="preload" as="script" href="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" async></script> <!-- JS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --> <script src="/kernel/assets/js/post.min.js" async></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script> <script src="/kernel/app.js" defer></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column"> <!-- The Side Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="nav-wrapper"><div id="profile-wrapper" class="d-flex flex-column"><div id="avatar" class="d-flex justify-content-center"> <a href="/kernel/" alt="avatar"> <img src="/kernel/assets/img/sample/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="profile-text mt-3"><div class="site-title"> <a href="/kernel/">Anarthal Kernel</a></div><div class="site-subtitle font-italic">A blog on data science and programming</div></div></div><ul class="nav flex-column"><li class="nav-item d-flex justify-content-center "> <a href="/kernel/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/kernel/tabs/categories/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/kernel/tabs/tags/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/kernel/tabs/archives/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/kernel/tabs/about/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></li></ul></div><div class="sidebar-bottom d-flex flex-wrap justify-content-around mt-4"> <a href="https://github.com/anarthal" target="_blank"> <i class="fab fa-github-alt"></i> </a> <a href="https://www.linkedin.com/in/ruben-perez-hidalgo" target="_blank"> <i class="fab fa-linkedin"></i> </a></div></div><!-- The Top Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/kernel/"> Posts </a> </span> <span>Deep dive into neural networks - multiclass classification</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"> <!-- Fixed kramdown code highlight rendering: https://github.com/penibelst/jekyll-compress-html/issues/101 https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901 --><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Deep dive into neural networks - multiclass classification</h1><div class="post-meta text-muted d-flex flex-column"><div> Posted <span class="timeago" data-toggle="tooltip" data-placement="bottom" title="Sun, Aug 23, 2020, 12:00 AM +0200"> Aug 23, 2020 <i class="unloaded">2020-08-23T00:00:00+02:00</i> </span> by <span class="author"> anarthal </span></div></div><div class="post-content"><p>Some machine learning problems involve classifying an object into one of N classes. These are called <a href="https://en.wikipedia.org/wiki/Multiclass_classification">multiclass classification</a> problems, as opposed to <a href="https://en.wikipedia.org/wiki/Binary_classification">binary classification</a>, where there is just a positive and a negative class. Handwritten digit recognition and image classification are two well-known instances of multiclass classification problems.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/kernel/assets/img/neural-networks-multiclass/multiclass.jpeg" alt="Multiclass" /></p><p>Image source: <a href="https://towardsdatascience.com/multi-class-classification-one-vs-all-one-vs-one-94daed32a87b">https://towardsdatascience.com/multi-class-classification-one-vs-all-one-vs-one-94daed32a87b</a></p><p>In this post we will explain how a neural network can be used to solve this problem. This is the second of a series of posts on neural networks I’ve been writing. If you are new to the topic, you may want to have a look into <a href="/kernel/posts/neural-networks/">the first one</a> before.</p><h2 id="problem-statement">Problem statement</h2><p>Let’s say we are working in an application for a factory processing fruits. Trucks bring oranges, lemons and limes mixed together. As a first step, a robot separates the fruits guided by a camera. Our task is to develop a model that classifies a fruit into one of the three groups given an input image. This is a multiclass classification problem with \(K = 3\) classes.</p><p>Each image can be translated into a set of input features \(x_1, x_2, ..., x_n\), with \(x_i \in \mathbb{R}\). A full discussion on the feature extraction process is beyond the scope of this post. As an option, we can understand the image as an array of numbers representing color intensities (one per pixel, for a grayscale image), and make each intensity an input feature. Other solutions may involve <a href="https://en.wikipedia.org/wiki/Autoencoder">autoencoders</a> and <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional</a> architectures.</p><p>Given an image’s features \(x_1, x_2, ..., x_n\), our model must predict a label \(y \in \{0, 1, 2\}\), with the following criteria:</p>\[\begin{matrix} y = 0 &amp; \Rightarrow &amp; Orange &amp; \\ y = 1 &amp; \Rightarrow &amp; Lemon &amp; \\ y = 2 &amp; \Rightarrow &amp; Lime &amp; \\ \end{matrix}\]<p>To train our model, we will have a collection of \(m\) correctly labeled images. We can represent these as a set of pairs \((x^{(i)}, y^{(i)})\), where \(x^{(i)} \in \mathbb{R}^n\) is the feature representation of the \(i\)th image, and \(y^{(i)} \in \{0, 1, 2\}\) tells us which fruit the image represents.</p><p>In the <a href="/kernel/posts/neural-networks/">previous post</a> we presented the following neural network, suitable for binary classification:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/kernel/assets/img/neural-networks/layers.png" alt="Neural network binary classification" /></p><p>This network needs a couple changes before it can be used for multiclass classification. We will go over them in the next sections.</p><h2 id="label-representation-one-hot-encoding">Label representation: one-hot encoding</h2><p>The label representation \(y \in \{0, 1, 2\}\) may seem natural to us, but doesn’t work well for neural network training, as it implies an ordering between categories. By using this representation we are telling our network that \(Orange &lt; Lemon &lt; Lime\), which does not make any sense.</p><p>Instead, we will use a <a href="https://en.wikipedia.org/wiki/One-hot">one-hot representation</a>. With this scheme, our labels \(y\) become 3-dimensional vectors, with each element representing whether the fruit belongs to a certain class or not (i.e. the first element tells us whether the fruit is an orange or not, the second one whether it’s a lemon, and so on).</p><p>Using this representation, our training labels become:</p>\[\begin{matrix} y = \begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix} &amp; \Rightarrow &amp; \text{Orange} \\ y = \begin{bmatrix} 0 \\ 1 \\ 0 \end{bmatrix} &amp; \Rightarrow &amp; \text{Lemon} \\ y = \begin{bmatrix} 0 \\ 0 \\ 1 \end{bmatrix} &amp; \Rightarrow &amp; \text{Lime} \\ \end{matrix}\]<p>Note that classes are mutually exclusive: a fruit may be an orange or a lemon, but not both at the same time! This implies that exactly one element in the label vector must be one, with the other ones being zero. That’s why the encoding scheme is called <em>one-hot</em>!</p><p>In the general case, we will use vectors \(y \in \mathbb{R}^K\), with \(K\) being the number of classes. If an object belong to class \(c\), the vector’s \(c\)‘th element will be a one and the rest will be zero.</p><h2 id="the-output-layer">The output layer</h2><p>In binary classification, the output layer produces a single value \(y_{prob}\), which we interpret as the probability of the object to belong to the positive class given the input features. This is coherent with labels, which are represented as a single value (0 or 1).</p><p>In multiclass classification we are using vectors of \(K\) elements as labels, instead. That means we will have to update our output layer to produce \(K\)-dimensional predictions. The new output vector \(y_{prob} \in \mathbb{R}^K\) will have as many numbers as possible classes. Each of these numbers will be between zero and one, and can be interpreted as the probability of the example to belong to each class. For example:</p>\[y_{prob} = \begin{bmatrix} 0.7 \\ 0.2 \\ 0.1 \end{bmatrix}\]<p>This means that our networks thinks there is a 70% chance that the input picture is an orange, a 20% chance that it’s a lemon, and a 10% chance that it’s a lime. The final prediction would be <em>orange</em>. Note that all the probabilities in the output vector sum 1. This is required because the output labels are mutually exclusive: one picture can’t be an orange and a lemon at the same time.</p><p>So what’s the actual change? We will just increase the number of units in the output layer to three!</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/kernel/assets/img/neural-networks-multiclass/layers.png" alt="Layers multiclass" /></p><h2 id="the-activation-function">The activation function</h2><p>In binary classification we used the sigmoid activation function for the output layer, as it guarantees that the output is between zero and one. Now that we have increased our output layer size, the sigmoid may not be the better choice. We could apply it independently to each output unit, but we would have no guarantee that the output probabilities add up to one, thus breaking our interpretation.</p><p>Instead, we will use the <a href="https://en.wikipedia.org/wiki/Softmax_function">softmax</a> activation function for the output layer. Given a vector \(\boldsymbol z \in \mathbb{R}^K\), the softmax function computes another vector of the same dimension, with its \(i\)th element being:</p>\[softmax(\boldsymbol z)[i] = \frac{e^{\boldsymbol z}[i]}{sum(e^{\boldsymbol z})} = \frac{e^{\boldsymbol z}[i]}{\sum_{c=0}^{K-1}e^{\boldsymbol z}[i]}\]<p>Where \(e^{\boldsymbol z}\) is the exponential function, applied element-wise to the vector \(z\), and the square brackets indicate array indexing. Note that we are dividing by the sum of the exponentials. This guarantees that, if we add all the elements produced by the softmax, the result will be 1.0.</p><p>With these considerations, the output layer will do the following:</p>\[\boldsymbol z^{[3]} = \boldsymbol W^{[3]} \boldsymbol a^{[2]} + \boldsymbol b^{[3]}\] \[\boldsymbol a^{[3]} = y_{prob} = softmax(\boldsymbol z^{[3]})\]<p>The matrix \(\boldsymbol W^{[3]}\) will have dimensions 3x2, thus guaranteeing that both \(\boldsymbol z^{[3]}\) and \(\boldsymbol a^{[3]}\) have as many elements as classes.</p><h2 id="the-loss-function">The loss function</h2><p>For binary classification we can use the log loss (also called the cross-entropy loss), with the following formulation:</p>\[L(y, y_{prob}) = - y \ log(y_{prob}) - (1 - y) log(1 - y_{prob})\]<p>Where \(y_{prob}\) is what our model predicted and \(y\) is the actual label. Recall that the loss function is defined for just one training example. To compute the total cost we would average over all the examples in our training set.</p><p>The form shown above is a particularization of the cross-entropy loss for two classes. For our example, we can use this generalization:</p>\[L(y, y_{prob}) = - y[0] \ log(y_{prob}[0]) - y[1] \ log(y_{prob}[1]) - y[2] \ log(y_{prob}[2])\]<p>An example is worth a thousand words, so go through one. We will examine how the loss function behaves for three different predictions for the same image. Let’s say that we are given a picture of an orange. With our one-hot encoding strategy, the label would be:</p>\[\text{The example was an orange} \Rightarrow y = \begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix}\]<p><strong>Case 1</strong>. The network works well for the example: it is 70% sure that what is saw was an orange.</p>\[y_{prob} = \begin{bmatrix} 0.7 \\ 0.2 \\ 0.1 \end{bmatrix}\] \[L(y, y_{prob}) = - 1 * log(0.7) - 0 * log(0.2) - 0 * log(0.1) = 0.3567\]<p><strong>Case 2</strong>. The network is unsure and thinks every fruit is equally likely.</p>\[y_{prob} = \begin{bmatrix} 0.33 \\ 0.33 \\ 0.33 \end{bmatrix}\] \[L(y, y_{prob}) = - 1 * log(0.33) - 0 * log(0.33) - 0 * log(0.33) = 1.1087\]<p><strong>Case 3</strong>. The network makes a mistake: it predicts a lime.</p>\[y_{prob} = \begin{bmatrix} 0.1 \\ 0.2 \\ 0.7 \end{bmatrix}\] \[L(y, y_{prob}) = - 1 * log(0.1) - 0 * log(0.2) - 0 * log(0.7) = 2.3026\]<p>The loss function’s behaviour seems coherent:</p><ul><li><strong>Case 1</strong>. If the network is confident about a prediction and it’s right, the cost is low.</li><li><strong>Case 2</strong>. If the network is uncertain, the cost is higher.</li><li><strong>Case 3</strong>. If the network is confident but the prediction ends up being wrong, the cost is the highest.</li></ul><p>Also notice that the loss function only pays attention to the predicted probability of the actual class. In this example, the actual class was the first one, so the loss function only cares about the first element of \(y_{prob}\).</p><p>For the general case with \(K\) classes, the cross-entropy loss has the following formulation:</p>\[L(y, y_{prob}) = \sum_{c=0}^{K-1} - y[c] \ log(y_{prob}[c])\]<p>If you want to dig deeper, <a href="https://towardsdatascience.com/cross-entropy-for-classification-d98e7f974451">this post</a> explores the cross-entropy loss with multiple classes in depth.</p><h2 id="conclusion">Conclusion</h2><p>That’s it! We now have all the elements in place to build a neural network that performs multiclass classification. We’ve covered the data format, the network architecture and the loss function. These are all the elements that we need to specify when creating a network using frameworks like <a href="https://keras.io/">Keras</a>.</p><p>In the next post we will apply these concepts by using <a href="https://keras.io/">Keras</a> to create and train a network to solve a classical handwritten digit recognition problem. See you soon!</p><h2 id="references">References</h2><ul><li>Deep Learning Specialization, Coursera courses by Andrew Ng: <a href="https://www.coursera.org/specializations/deep-learning">https://www.coursera.org/specializations/deep-learning</a></li><li>Cross-entropy for classification, by Vlastimil Martinek: <a href="https://towardsdatascience.com/cross-entropy-for-classification-d98e7f974451">https://towardsdatascience.com/cross-entropy-for-classification-d98e7f974451</a></li><li>Choosing the right Encoding method-Label vs OneHot Encoder, by Raheel Shaikh: <a href="https://towardsdatascience.com/choosing-the-right-encoding-method-label-vs-onehot-encoder-a4434493149b">https://towardsdatascience.com/choosing-the-right-encoding-method-label-vs-onehot-encoder-a4434493149b</a></li><li>Multi-class Classification — One-vs-All &amp; One-vs-One, by Amey Band: <a href="https://towardsdatascience.com/multi-class-classification-one-vs-all-one-vs-one-94daed32a87b">https://towardsdatascience.com/multi-class-classification-one-vs-all-one-vs-one-94daed32a87b</a></li></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/kernel/categories/data-science/'>Data Science</a>, <a href='/kernel/categories/machine-learning/'>Machine Learning</a>, <a href='/kernel/categories/deep-learning/'>Deep Learning</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/kernel/tags/machinelearning/" class="post-tag no-text-decoration" >machinelearning</a> <a href="/kernel/tags/deeplearning/" class="post-tag no-text-decoration" >deeplearning</a> <a href="/kernel/tags/classification/" class="post-tag no-text-decoration" >classification</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><!-- Post sharing snippet v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://anarthal.github.io/kernel/posts/neural-networks-multiclass/" data-toggle="tooltip" data-placement="top" title="Linkedin" target="_blank"> <i class="fa-fw fab fa-linkedin"></i> </a> <a href="https://twitter.com/intent/tweet?text=Deep dive into neural networks - multiclass classification - Anarthal Kernel&url=https://anarthal.github.io/kernel/posts/neural-networks-multiclass/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Deep dive into neural networks - multiclass classification - Anarthal Kernel&u=https://anarthal.github.io/kernel/posts/neural-networks-multiclass/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Deep dive into neural networks - multiclass classification - Anarthal Kernel&url=https://anarthal.github.io/kernel/posts/neural-networks-multiclass/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><!-- The Pannel on right side (Desktop views) v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><h3 data-toc-skip>Recent Update</h3><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/kernel/posts/neural-networks/">Deep dive into neural networks - the basics</a></li><li><a href="/kernel/posts/underfitting-overfitting/">Underfitting, overfitting and model complexity</a></li><li><a href="/kernel/posts/logistic-regression/">Logistic regression</a></li></ul></div><div id="access-tags"><h3 data-toc-skip>Trending Tags</h3><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/kernel/tags/machinelearning/">machinelearning</a> <a class="post-tag" href="/kernel/tags/classification/">classification</a> <a class="post-tag" href="/kernel/tags/supervised/">supervised</a> <a class="post-tag" href="/kernel/tags/sklearn/">sklearn</a> <a class="post-tag" href="/kernel/tags/python/">python</a> <a class="post-tag" href="/kernel/tags/deeplearning/">deeplearning</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><h3 data-toc-skip class="pl-3 pt-2 mb-2">Contents</h3><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div id="post-extend-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"> <!-- Navigation buttons at the bottom of the post. v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --><div class="post-navigation d-flex justify-content-between"> <a href="/kernel/posts/neural-networks/" class="btn btn-outline-primary"><p>Deep dive into neural networks - the basics</p></a> <span class="btn btn-outline-primary disabled"><p>-</p></span></div><!-- The Disqus lazy loading. Powered by: https://osvaldas.info/lazy-loading-disqus-comments v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung MIT License --><div id="disqus" class="pt-2 pb-4"><p class="font-italic text-center text-muted small">Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div><script src="/kernel/assets/js/lib/jquery.disqusloader.min.js"></script> <script> var options = { scriptUrl: '//anarthal-kernel.disqus.com/embed.js', disqusConfig: function() { this.page.url = 'https://anarthal.github.io/kernel/posts/neural-networks-multiclass/'; this.page.identifier = '/posts/neural-networks-multiclass/'; } }; $.disqusLoader('#disqus', options); </script> <!-- Recommend the other 3 posts according to the tags and categories of the current post, if the number is not enough, use the other latest posts to supplement. v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div id="related-posts" class="mt-4 mb-2 mb-sm-4 pb-2"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/kernel/posts/neural-networks/"><div class="card-body"> <span class="timeago small"> Aug 5, 2020 <i class="unloaded">2020-08-05T00:00:00+02:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Deep dive into neural networks - the basics</h3><div class="text-muted small"><p>They are on everyone’s lips: every single post today seems to talk about deep neural networks and the bewildering variety of applications they are used for. Speech recognition, computer vision, nat...</p></div></div></a></div><div class="card"> <a href="/kernel/posts/logistic-regression/"><div class="card-body"> <span class="timeago small"> Jul 8, 2020 <i class="unloaded">2020-07-08T00:00:00+02:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Logistic regression</h3><div class="text-muted small"><p>In this post I will talk about one of the most basic models in Machine Learning: logistic regression. This post doesn’t assume any previous knowledge of logistic regression. Some prior knowledge on...</p></div></div></a></div><div class="card"> <a href="/kernel/posts/underfitting-overfitting/"><div class="card-body"> <span class="timeago small"> Jul 16, 2020 <i class="unloaded">2020-07-16T00:00:00+02:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Underfitting, overfitting and model complexity</h3><div class="text-muted small"><p>In this post I will talk about the underfitting and overfitting phenomena, and how model complexity affects them. I will also explain the bias-variance trade-off. We will demonstrate these concept...</p></div></div></a></div></div></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('#post-wrapper img'); const observer = lozad(imgs); observer.observe(); </script> <!-- The Footer v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2020 <a href="https://github.com/anarthal">Ruben Perez</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy/">Chirpy</a> theme.</p></div></div></footer></div><!-- The Search results v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/kernel/tags/machinelearning/">machinelearning</a> <a class="post-tag" href="/kernel/tags/classification/">classification</a> <a class="post-tag" href="/kernel/tags/supervised/">supervised</a> <a class="post-tag" href="/kernel/tags/sklearn/">sklearn</a> <a class="post-tag" href="/kernel/tags/python/">python</a> <a class="post-tag" href="/kernel/tags/deeplearning/">deeplearning</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <!-- The GA snippet v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-174570044-1', 'auto'); ga('send', 'pageview'); </script> <!-- Jekyll Simple Search loader v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/kernel/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://anarthal.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
